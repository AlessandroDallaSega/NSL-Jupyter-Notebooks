{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85b8c4a9-2394-49f1-9a7f-5cc160471091",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> Numerical Simulation Laboratory </span>\n",
    "## <span style=\"color:brown\"> Python Exercise 11 </span>\n",
    "## <span style=\"color:orange\"> Keras - Neural Network regression </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148f0c69-9d6c-42f3-93e1-a9c47456cba1",
   "metadata": {},
   "source": [
    "### Overview \n",
    "\n",
    "In this notebook our task will be to perform machine learning regression on noisy data with a Neural Network (NN).\n",
    "\n",
    "We will explore how the ability to fit depends on the structure of the NN. The goal is also to build intuition about why prediction is difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26f3d45-fbba-4737-b495-fc0c63bde4d9",
   "metadata": {},
   "source": [
    "### The Prediction Problem\n",
    "\n",
    "Consider a probabilistic process that gives rise to labeled data $(x,y)$. The data is generated by drawing samples from the equation\n",
    "\n",
    "$$\n",
    "    y_i= f(x_i) + \\eta_i,\n",
    "$$\n",
    "\n",
    "where $f(x_i)$ is some fixed, but (possibly unknown) function, and $\\eta_i$ is a Gaussian, uncorrelate noise variable such that\n",
    "\n",
    "$$\n",
    "\\langle \\eta_i \\rangle=0\n",
    "$$\n",
    "$$\n",
    "\\langle \\eta_i \\eta_j \\rangle = \\delta_{ij} \\sigma\n",
    "$$\n",
    "\n",
    "We will refer to the $f(x_i)$ as the **true features** used to generate the data. \n",
    "\n",
    "To make predictions, we will consider a NN that depends on its parameters, weights and biases. The functions that the NN can model respresent the **model class** that we are using to try to model the data and make predictions.\n",
    "\n",
    "To learn the parameters of the NN, we will train our models on a **training data set** and then test the effectiveness of the NN on a *different* dataset, the **validation data set**. The reason we must divide our data into a training and test dataset is that the point of machine learning is to make accurate predictions about new data we have not seen.\n",
    "\n",
    "To measure our ability to predict, we will learn our parameters by fitting our training dataset and then making predictions on our test data set. One common measure of predictive  performance of our algorithm is to compare the predictions,$\\{y_j^\\mathrm{pred}\\}$, to the true values $\\{y_j\\}$. A commonly employed measure for this is the sum of the mean square-error (MSE) on the test set:\n",
    "$$\n",
    "MSE= \\frac{1}{N_\\mathrm{test}}\\sum_{j=1}^{N_\\mathrm{test}} (y_j^\\mathrm{pred}-y_j)^2\n",
    "$$\n",
    "\n",
    "We will try to get a qualitative picture by examining plots on validation and training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccb40d7-9765-4013-a14a-b8013040abd0",
   "metadata": {},
   "source": [
    "# Exercise 11.1\n",
    "\n",
    "In this section, we attempt to fit a linear function:\n",
    "\n",
    "$f(x) = 2x + 1$\n",
    "\n",
    "for $x \\in [-1, 1]$. For this task, a single neuron is sufficient. Let's evaluate how the quality of the fit depends on a series of parameters:\n",
    "\n",
    "- The number of training epochs of the model $N_{epoch}$\n",
    "- The number of training data points $N_{train}$\n",
    "- The noise in the data $\\sigma$\n",
    "\n",
    "To explore the dependence on these parameters, we started with the values $N_{epoch} = 30$, $N_{train} = 1000$, $\\sigma = 0.3$ and increased and decreased them one by one, keeping the others fixed. The evaluation of the result is based on a cost function (mean squared error). We can also compare the model's predictions with the original line and its respective parameters (weight and bias of the neuron, angular coefficient, and y-intercept of the line). In all cases, we maintained a ratio of 10:1 between the number of training and validation data points.\n",
    "\n",
    "Let's report the results obtained with the initial parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cbc084-6185-4407-a943-c2f539c8f249",
   "metadata": {},
   "source": [
    "![](Dati_iniziali.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a6a045-fa82-41b5-b9fb-f258db36ca48",
   "metadata": {},
   "source": [
    "## Varying the number of epochs ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846fe4b0-6e3e-440c-9698-e2d20b55fb20",
   "metadata": {},
   "source": [
    "With $N_{epochs} = 300$ we obtain $m=2.0014355$ and $b=1.0067096$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d67262-2514-4e41-9c10-0730becfae98",
   "metadata": {},
   "source": [
    "![](Nepochs_300.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e35cb29-1ab9-4438-82d8-109ca7b92a5f",
   "metadata": {},
   "source": [
    "With $N_{epochs} = 5$ we obtain $m=1.636246$ and $b=0.96392345$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccb59a9-0618-4aef-8b9a-14c281a4d23f",
   "metadata": {},
   "source": [
    "![](Nepochs_5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81a9fa5-b8d5-428a-99e3-e44e2ed36d09",
   "metadata": {},
   "source": [
    "## Varying $N_{train}$ and $N_{valid}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64eb34d5-16ff-4a52-839e-40afd82abc66",
   "metadata": {},
   "source": [
    "With $N_{train}=100$ and $N_{valid}=10$ we obtain $m=1.7317797$ and $b=0.90938854$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e54eb62-b395-46e4-87e0-e23b5ba6cdfc",
   "metadata": {},
   "source": [
    "![](Ntrain_100.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bce450-8867-4226-9930-47bd81aee452",
   "metadata": {},
   "source": [
    "With $N_{train}=2500$ and $N_{valid}=250$ we obtain $m=1.9870311$ and $b=0.9919341$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ba8085-c2ac-436a-86f7-16f13edeeebe",
   "metadata": {},
   "source": [
    "![](Ntrain_2500.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0591c1eb-2e56-4d2f-8927-827ca2e97083",
   "metadata": {},
   "source": [
    "## Varying $\\sigma$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f6cf07-0d9b-4e38-823e-fa0c4acf9e19",
   "metadata": {},
   "source": [
    "With $\\sigma= 0.01$ we obtain $m=1.9991245$ and $b=1.0001116$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d972f0c-90da-440b-b2f4-9fb43e272848",
   "metadata": {},
   "source": [
    "![](Sigma_001.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cd9d29-7d3d-4cb7-ad7c-3ccc52866943",
   "metadata": {},
   "source": [
    "With $\\sigma= 2$ we obtain $m=1.9992996$ and $b=1.0387775$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33497cc-508d-41b7-b1ec-7a65d193657a",
   "metadata": {},
   "source": [
    "![](Sigma_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88206096-6691-433b-8ceb-72a51e0759d4",
   "metadata": {},
   "source": [
    "We observed that varying $N_{train}$ and $N_{valid}$ impacts the variation of the results more significantly than changing the number of epochs. One might assume that increasing the number of epochs would lead to better results; however, this is not necessarily the case. In fact, increasing the number of epochs can lead to overfitting rather than improved performance. Additionally, varying $\\sigma$ greatly affects the results, which is expected because changing the value of $\\sigma$ significantly alters the initial data distribution. Lastly, it is worth noting that we achieved reasonable results even for a very noisy system ($\\sigma = 2$).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374cd816-dd6d-40f4-a187-269cb079d10e",
   "metadata": {},
   "source": [
    "# Exercise 11.2\n",
    "\n",
    "We want to perform the fit of a more complex polynomial function:\n",
    "\n",
    "$f(x) = 4 - 3x - 2x^2 + 3x^3$\n",
    "\n",
    "for $x \\in [-1, 1]$. For this purpose, we experiment with different neuron arrangements that could be more or less effective. We have chosen $N_{train} = 5000$, $N_{valid} = 500$, $\\sigma = 0.3$, $N_{epoch} = 80$. The points of the validation set are represented here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb155d1f-e822-4757-8933-2e2d3cb56d31",
   "metadata": {},
   "source": [
    "![](Dataset_112.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10357887-3efd-4bef-a916-27cbf6854828",
   "metadata": {},
   "source": [
    "## First Option: Single Hidden Layer\n",
    "\n",
    "For our initial approach, we considered a neural network with only one hidden layer. We varied the number of neurons in this layer, testing with $N = 6$, $50$, and $100$. The structure of these neural networks can be represented as $1|N|1$, where:\n",
    "\n",
    "- The first \"1\" represents the input layer with one neuron (for $x$)\n",
    "- $N$ represents the number of neurons in the hidden layer (varying as 6, 50, or 100)\n",
    "- The last \"1\" represents the output layer with one neuron (for $f(x)$)\n",
    "\n",
    "Below, graphs illustrating:\n",
    "\n",
    "1. The cost function's evolution during training\n",
    "2. The model's predictions compared to the true function\n",
    "\n",
    "These visualizations will help us assess the performance of each network configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b3a26a-914a-4607-a1b7-5f55c09c80ee",
   "metadata": {},
   "source": [
    "## 1 layer and 6 neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba04f163-c01e-4627-94ac-298235835073",
   "metadata": {},
   "source": [
    "![](1layer6neuroni.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2094d20a-cc4d-4179-ba7b-66a82ccfe1d7",
   "metadata": {},
   "source": [
    "## 1 layer and 50 neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499b0180-d7ae-4d62-acfa-4a5bb0efcc5d",
   "metadata": {},
   "source": [
    "![](1layer50neuroni.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d9c174-8439-4959-b8d1-23016601b8c4",
   "metadata": {},
   "source": [
    "## 1 layer and 100 neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb20305-9109-49a3-9b4e-5ff498395e56",
   "metadata": {},
   "source": [
    "![](1layer100neuroni.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5107034-4f77-42e6-a5a7-08bd19d4ca27",
   "metadata": {},
   "source": [
    "Certainly, increasing the number of neurons in a single layer improves the model's fit. However, we observed that the neural network's behavior remains quite similar when increasing from 50 to 100 neurons. Moreover, its ability to predict function values outside the original range is very limited."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ced586-cbcc-4912-b563-b2a43ce3e364",
   "metadata": {},
   "source": [
    "## Second Option: Four Hidden Layers\n",
    "\n",
    "For our next approach, we explore a deeper neural network architecture. This structure consists of five hidden layers, each containing four neurons. The complete architecture can be represented as:\n",
    "\n",
    "$1|10|10|10|10|1$\n",
    "\n",
    "This notation describes:\n",
    "- An input layer with 1 neuron\n",
    "- Four hidden layers, each with 10 neurons\n",
    "- An output layer with 1 neuron\n",
    "\n",
    "This deeper structure allows for more complex feature extraction and potentially better approximation of our polynomial function.\n",
    "\n",
    "Below, we present graphs similar to those in the first option:\n",
    "\n",
    "1. The evolution of the cost function during training\n",
    "2. The model's predictions compared to the true polynomial function\n",
    "\n",
    "These visualizations will help us assess whether this deeper architecture provides any advantages over the simpler models from our first option."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6435e263-4162-4af8-bcf7-02b21b5d904f",
   "metadata": {},
   "source": [
    "![](4layer10neuroni.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f539b3-b015-4ef5-a9fd-9aa292da87af",
   "metadata": {},
   "source": [
    "In this scenario, the model fits the data quite well, although not better than when using just one hidden layer. Also, it still faces challenges when predicting values outside the original range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47672614-0e24-4108-a8fe-9b90e12ccaf9",
   "metadata": {},
   "source": [
    "### Exercise 11.3\n",
    "  \n",
    "Try to extend the model to fit a simple trigonometric 2D function such as $f(x,y) = \\sin(x^2+y^2)$ in the range $x \\in [-3/2,3/2]$ and $y \\in [-3/2,3/2]$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eb17f0-a3bb-4683-937f-1d897372b32e",
   "metadata": {},
   "source": [
    "After analyzing the results of the previous exercises, we decided to use a neural network structured with 3 hidden layers, each containing a different number of neurons. After experimenting with various configurations, we settled on the following structure: $2|35|25|20|1$. In earlier exercises, we observed that increasing the number of neurons in a layer improves the fitting. We believe that, given the complexity of the function to evaluate, using more than one hidden layer will also be beneficial. However, it is worth noting that in exercise 11.2, adding more layers did not necessarily result in better fitting. We also set $N_{train}=10000$, $N_{epoch}=100$ and $\\sigma=0.2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68a0748-68b1-4a28-839c-8a58f2720ef4",
   "metadata": {},
   "source": [
    "We show in the following graph the function we want to fit and the validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac95f480-f7b3-4530-989d-62682b6003b1",
   "metadata": {},
   "source": [
    "![](Dataset113.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1a14de-2ed0-4c40-ac7b-a2b414495e31",
   "metadata": {},
   "source": [
    "Next, we present the graphs of the cost function and the model's predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe379f4-2bd2-4051-90a4-cdb118e69bf6",
   "metadata": {},
   "source": [
    "![](Lossandpredict113.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8039dafa-535e-46f2-9e09-e94182260888",
   "metadata": {},
   "source": [
    "We can deduce that the fit is quite good, with the exception of the points at the \"corners\" of the domain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f809c0-d681-4ba6-8200-91aa4c0cad09",
   "metadata": {},
   "source": [
    "All the images and data shown in this file are obtained by running the code in LSN_Exercises_11.ipynb."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
